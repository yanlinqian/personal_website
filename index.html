<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Yanlin Qian</title>

  <meta name="author" content="Yanlin Qian">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yanlin Qian</name>
              </p>
              <p>
                I am a senior research engineer (A) at Huawei Camera Team, where I work on computational photography and computer vision.
              </p>
              <p>
                At Huawei, I work on problems for example auto-white balance, illumination reflentance spectra estimation and matrix factorization.
                I will graduate from Phd in <a href="www.tuni.fi">Tampere University</a> in June 2020,
                where I was supervised by Prof. <a href="http://vision.cs.tut.fi/personal/JoniKamarainen/">Joni-Kristian Kämäräinen</a> and Prof. <a href="http://cmp.felk.cvut.cz/~matas/">Jiri Matas</a>.

              </p>
              <p style="text-align:center">
                <a href="mailto:qianyanlin619812051@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.co.uk/citations?user=EMnEhLIAAAAJ&hl=en">Google Scholar</a>
                <!-- &nbsp/&nbsp -->
                <!-- <a href="https://www.facebook.com/barron.jon">Social</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yanlin_pencil.png"><img style="width:60%;max-width:50%" alt="profile photo" src="images/yanlin_pencil.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>

                <!-- I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. Representative papers are <span class="highlight">highlighted</span>. -->
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- paper 1 -->
          <!-- <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
        <em>arXiv</em>, 2020
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
        /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">video</a>
        /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr> -->




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img style="width:115%;max-width:115%" src="images/graypixel2019.png" alt="graypixel2019.png" style="border-style: none"> -->
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/tcc.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/tcc_48.jpg' width="130">
              </div>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2003.03763">
                <papertitle>A Benchmark for Temporal Color Constancy</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>, Jani Käpylä, Joni-Kristian Kämäräinen, Samu Koskinen, Jiri Matas</a>
              <br>
              <em>arxiv</em>
              <br>
              <!-- <a href="https://github.com/yanlinqian/Grayness-Index">code</a>/ -->
               <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> /  -->
              <a href="data/qian2020benchmark.bib">bibtex</a>
              <p> Revisiting Temporal color constancy. We propose a 600-video temporal color constancy dataset, and a smaller better faster net called TCC-Net.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:100%;max-width:100%" src="images/c4_track.png" alt="c4_track.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/1912.11180">
                <papertitle>Cascading Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <a>Huanglin Yu, Ke Chen, Kaiqi Wang, Yanlin Qian, Zhaoxiang Zhang, Kui Jia</a>
              <br>
              <em>AAAI</em>,2020
              <br>
              <a href="https://github.com/yhlscut/C4">code</a>/
               <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> /  -->
              <a href="data/yu2019cascading.bib">bibtex</a>
              <p> We cascade SqueezeNet-based bricks obtain SotA results on Gehlershi and NUS 8-camera datasets.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:115%;max-width:100%" src="images/graypixel2019.png" alt="graypixel2019.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Qian_On_Finding_Gray_Pixels_CVPR_2019_paper.pdf">
                <papertitle>On Finding Gray Pixels</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>, Joni Kämäräinen, Jarno Nikkanen, Jiri Matas</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://github.com/yanlinqian/Grayness-Index">code</a>/
              <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> / <a href="data/qian2019finding.bib">bibtex</a>
              <p>Gray (achromatic) pixels can be used for illumination estimation. This paper tells how to pick up them ACCURATELY.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:115%;max-width:100%" src="images/graypixel_meanshift.png" alt="graypixel_meanshift.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=7&cad=rja&uact=8&ved=2ahUKEwiV0Oqk6IrpAhVDXM0KHQCZBrQQFjAGegQIChAB&url=https%3A%2F%2Fwww.scitepress.org%2FPapers%2F2019%2F74069%2F74069.pdf&usg=AOvVaw3hExEfQYaZ16oKQp84XRWZ">
                <papertitle>Revisiting Gray Pixel for Statistical Illumination Estimation</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>, Said Pertuz, Joni Kämäräinen, Jarno Nikkanen, Jiri Matas</a>
              <br>
              <em>VISSAP</em>, 2019
              <br>
              <a href="https://github.com/yanlinqian/Mean-shifted-Gray-Pixel">code</a>
              / <a href="data/yanlin2019vissap.bib">bibtex</a>
              <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> / <a href="data/qian2019finding.bib">bibtex</a> -->
              <p>Gray (achromatic) pixels can be used for illumination estimation. This paper tells how to pick up them using Clustering.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:115%;max-width:100%" src="images/flashgraypixel.png" alt="flashgraypixel.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="ftp://cmp.felk.cvut.cz/pub/cvl/articles/matas/qian-2019-flash_gray_pixel-icip.pdf">
                <papertitle>Flash Lightens Gray Pixels</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>, Song Yan, Joni Kämäräinen, Jiri Matas</a>
              <br>
              <em>ICIP</em>, 2019
              <br>
              <a href="data/yanlin2019icip.bib">bibtex</a>
              <!-- <a href="https://github.com/yanlinqian/Mean-shifted-Gray-Pixel">code</a> -->
              <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> / <a href="data/qian2019finding.bib">bibtex</a> -->
              <p>Gray (achromatic) pixels can be used for illumination estimation. This paper tells how to pick up them with the help of flash photography.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:115%;max-width:100%" src="images/challenge.png" alt="challenge.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8868451/">
                <papertitle>Fast Fourier Color Constancy and Grayness Index for ISPA Illumination Estimation Challenge</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>,Ke Chen, Huanglin Yu</a>
              <br>
              <em>ISPA, International Workshop on Color Vision</em>, 2019
              <br>
              <a href="data/qian2019fast.bib">bibtex</a> /
              <a href="https://www.isispa.org/illumination-estimation-challenge">Leaderboard Page</a>
              <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> / <a href="data/qian2019finding.bib">bibtex</a> -->
              <p>We briefly introduce two submissions to the Illumination Estimation Challenge, in the Int'l Workshop on Color Vision, affiliated to the 11th Int'l Symposium on Image and Signal Processing and Analysis. The fourier-transform-based submission is ranked 3rd, and the statistical Gray-pixel-based one ranked 6th.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img style="width:115%;max-width:115%" src="images/graypixel2019.png" alt="graypixel2019.png" style="border-style: none"> -->
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/tcc.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/tcc_48.jpg' width="130">
              </div>
            </td>
            <td width="75%" valign="middle">
              <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Qian_Recurrent_Color_Constancy_ICCV_2017_paper.pdf">
                <papertitle>Recurrent Color Constancy</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>, Ke Chen, Joni Kämäräinen, Jarno Nikkanen, Jiri Matas</a>
              <br>
              <em>ICCV</em>, 2017
              <br>
              <!-- <a href="https://github.com/yanlinqian/Grayness-Index">code</a>/ -->
               <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> /  -->
              <a href="data/qian2017recurrent.bib">bibtex</a>
              <p> Temporal color constancy: measuring the illumination of the captured image based on image deque. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img style="width:115%;max-width:100%" src="images/msvr.png" alt="msvr.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="http://vision.cs.tut.fi/data/publications/icpr2016_dcnn_colour_constancy.pdf">
                <papertitle>Deep Structured-Output Regression Learning for Computational Color Constancy</papertitle>
              </a>
              <br>
              <a><strong>Yanlin Qian</strong>, Ke Chen, Joni-Kristian Kamarainen, Jarno Nikkanen, Jiri Matas</a>
              <br>
              <em>ICPR</em>, 2016
              <br>
              <a href="data/yanlin2016icpr.bib">bibtex</a>
              <!-- <a href="https://github.com/yanlinqian/Mean-shifted-Gray-Pixel">code</a> -->
              <!-- <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=2ahUKEwjk9OSG8_joAhWswcQBHTatBC4QFjABegQIBxAB&url=http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_CVPR_2019%2Fsupplemental%2FQian_On_Finding_Gray_CVPR_2019_supplemental.pdf&usg=AOvVaw1n3WylQjMle__9zwfIX10m">supplement</a> / <a href="data/qian2019finding.bib">bibtex</a> -->
              <p>Illumination estimation based on VGG and AlexNet feature map and multi-output regression. This is my first paper.</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>More</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <!-- <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td> -->
          </tr>
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr> -->
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
